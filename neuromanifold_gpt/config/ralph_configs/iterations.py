"""Ralph Loop iteration configurations using composition pattern.

This module defines all Ralph Loop experimental configurations using the
RalphConfigBuilder pattern. Each iteration is a function returning a
RalphBaseConfig with specific parameter overrides.

Generated by scripts/migrate_ralph_configs.py
"""

from ..ralph_base import RalphBaseConfig
from ..ralph_builder import RalphConfigBuilder

# Ralph Loop Iteration 1 - Tiny config for 6GB GPU, sub-100s training
# GOALS: val_loss < 1.5, training_time < 100s
# Data


def ralph_iter1() -> RalphBaseConfig:
    """Ralph iteration 1 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            batch_size=32,
            dropout=0.0,
            eval_interval=200,
            eval_iters=20,
            gradient_accumulation_steps=2,
            learning_rate=0.001,
            lr_decay_iters=500,
            max_iters=500,
            n_embd=256,
            n_fhn_steps=1,
            n_head=4,
            n_layer=2,
            num_workers=2,
            out_dir="out-ralph-iter1",
            sample_interval=500,
            use_mhc=True,
            warmup_iters=100,
        )
        .build()
    )


# Ralph Loop Iteration 2 - Optimized for speed
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter2() -> RalphBaseConfig:
    """Ralph iteration 2 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=64,
            dropout=0.0,
            eval_interval=250,
            learning_rate=0.003,
            log_interval=100,
            lr_decay_iters=1200,
            max_iters=1200,
            min_lr=0.0003,
            n_embd=192,
            n_fhn_steps=1,
            n_head=4,
            n_layer=4,
            out_dir="out-ralph-iter2",
            use_mhc=True,
        )
        .build()
    )


# Ralph Loop Iteration 3 - Balanced model for quality
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter3() -> RalphBaseConfig:
    """Ralph iteration 3 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            batch_size=32,
            eval_interval=250,
            learning_rate=0.003,
            log_interval=100,
            min_lr=0.0003,
            n_embd=288,
            n_fhn_steps=1,
            n_layer=4,
            out_dir="out-ralph-iter3",
        )
        .build()
    )


# Ralph Loop Iteration 4 - Max iterations within 100s
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter4() -> RalphBaseConfig:
    """Ralph iteration 4 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            batch_size=32,
            eval_interval=300,
            learning_rate=0.003,
            log_interval=100,
            lr_decay_iters=1800,
            max_iters=1800,
            min_lr=0.0003,
            n_embd=288,
            n_fhn_steps=1,
            n_layer=4,
            out_dir="out-ralph-iter4",
        )
        .build()
    )


# Ralph Loop Iteration 5 - Fast model, max iterations in 100s
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter5() -> RalphBaseConfig:
    """Ralph iteration 5 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=64,
            dropout=0.0,
            eval_interval=300,
            learning_rate=0.006,
            log_interval=100,
            lr_decay_iters=1200,
            max_iters=1200,
            min_lr=0.0006,
            n_embd=192,
            n_fhn_steps=1,
            n_head=4,
            n_layer=4,
            out_dir="out-ralph-iter5",
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 6 - Compiled model for max speed
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter6() -> RalphBaseConfig:
    """Ralph iteration 6 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=64,
            compile_model=True,
            dropout=0.0,
            eval_interval=400,
            learning_rate=0.003,
            log_interval=100,
            lr_decay_iters=2000,
            max_iters=2000,
            min_lr=0.0003,
            n_embd=192,
            n_fhn_steps=1,
            n_head=4,
            n_layer=4,
            out_dir="out-ralph-iter6",
        )
        .build()
    )


# Ralph Loop Iteration 7 - Baseline GPT (no NeuroManifold)
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter7() -> RalphBaseConfig:
    """Ralph iteration 7 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            dropout=0.2,
            learning_rate=0.0015,
            lr_decay_iters=875,
            max_iters=875,
            model_type="baseline",
            out_dir="out-ralph-iter7",
            use_fhn_imex=False,
        )
        .build()
    )


# Ralph Loop Iteration 8 - Aggressive baseline GPT
# GOALS: val_loss < 1.5, training_time < 100s
# Last run: 107s @ 920 iters, val_loss=1.566


def ralph_iter8() -> RalphBaseConfig:
    """Ralph iteration 8 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            dropout=0.15,
            lr_decay_iters=850,
            max_iters=850,
            min_lr=0.0002,
            model_type="baseline",
            out_dir="out-ralph-iter8",
            use_fhn_imex=False,
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 9 - Use time headroom for more iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Last run: 87s @ 850 iters, val_loss=1.559 (9.02 it/s)
# We have 13s headroom = ~117 more iters


def ralph_iter9() -> RalphBaseConfig:
    """Ralph iteration 9 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            dropout=0.15,
            lr_decay_iters=900,
            max_iters=900,
            min_lr=0.0002,
            model_type="baseline",
            out_dir="out-ralph-iter9",
            use_fhn_imex=False,
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 10 - Final push for val_loss < 1.5
# GOALS: val_loss < 1.5, training_time < 100s
# Last run: 98s @ 900 iters, val_loss=1.530 (8.06 it/s)
# We have 2s headroom = ~16 more iters


def ralph_iter10() -> RalphBaseConfig:
    """Ralph iteration 10 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            dropout=0.15,
            lr_decay_iters=916,
            max_iters=916,
            min_lr=0.0002,
            model_type="baseline",
            out_dir="out-ralph-iter10",
            use_fhn_imex=False,
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 11 - Higher LR to converge faster
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 900 iters fit in 98s, use higher LR to converge faster


def ralph_iter11() -> RalphBaseConfig:
    """Ralph iteration 11 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            dropout=0.15,
            learning_rate=0.0025,
            lr_decay_iters=900,
            max_iters=900,
            min_lr=0.00025,
            model_type="baseline",
            out_dir="out-ralph-iter11",
            use_fhn_imex=False,
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 12 - Lower dropout for faster convergence
# GOALS: val_loss < 1.5, training_time < 100s
# Best so far: iter9 @ 98s, val_loss=1.530 with LR=2e-3, dropout=0.15
# Try: dropout=0.1 for less regularization


def ralph_iter12() -> RalphBaseConfig:
    """Ralph iteration 12 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            lr_decay_iters=900,
            max_iters=900,
            min_lr=0.0002,
            model_type="baseline",
            out_dir="out-ralph-iter12",
            use_fhn_imex=False,
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 13 - Minimize eval overhead
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: eval_interval=200 to reduce eval overhead, 880 iters


def ralph_iter13() -> RalphBaseConfig:
    """Ralph iteration 13 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=200,
            eval_iters=5,
            log_interval=100,
            lr_decay_iters=880,
            max_iters=880,
            min_lr=0.0002,
            model_type="baseline",
            out_dir="out-ralph-iter13",
            use_fhn_imex=False,
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 14 - Use 3s headroom for more iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Last: 97s @ 880 iters @ 8.22 it/s, val_loss=1.523
# Add ~25 iters to use the 3s headroom


def ralph_iter14() -> RalphBaseConfig:
    """Ralph iteration 14 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=200,
            eval_iters=5,
            log_interval=100,
            lr_decay_iters=905,
            max_iters=905,
            min_lr=0.0002,
            model_type="baseline",
            out_dir="out-ralph-iter14",
            use_fhn_imex=False,
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 15 - Fine-tune iteration count
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 895 iters should be ~99s at 8 it/s


def ralph_iter15() -> RalphBaseConfig:
    """Ralph iteration 15 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=200,
            eval_iters=5,
            log_interval=100,
            lr_decay_iters=895,
            max_iters=895,
            min_lr=0.0002,
            model_type="baseline",
            out_dir="out-ralph-iter15",
            use_fhn_imex=False,
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 16 - Gradient accumulation for better convergence
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: gradient_accumulation_steps=2 for effective batch=128
# Fewer steps needed with larger effective batch


def ralph_iter16() -> RalphBaseConfig:
    """Ralph iteration 16 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_iters=5,
            gradient_accumulation_steps=2,
            learning_rate=0.003,
            lr_decay_iters=450,
            max_iters=450,
            min_lr=0.0003,
            model_type="baseline",
            out_dir="out-ralph-iter16",
            use_fhn_imex=False,
            warmup_iters=15,
        )
        .build()
    )


# Ralph Loop Iteration 17 - No dropout for fastest convergence
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: dropout=0 for no regularization noise


def ralph_iter17() -> RalphBaseConfig:
    """Ralph iteration 17 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            dropout=0.0,
            eval_interval=200,
            eval_iters=5,
            log_interval=100,
            lr_decay_iters=895,
            max_iters=895,
            min_lr=0.0002,
            model_type="baseline",
            out_dir="out-ralph-iter17",
            use_fhn_imex=False,
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 18 - More weight decay to reduce overfitting
# GOALS: val_loss < 1.5, training_time < 100s
# Best config so far: dropout=0.1, weight_decay=0.1 → val_loss=1.514
# Try: weight_decay=0.15 to reduce gap between train/val


def ralph_iter18() -> RalphBaseConfig:
    """Ralph iteration 18 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=200,
            eval_iters=5,
            log_interval=100,
            lr_decay_iters=895,
            max_iters=895,
            min_lr=0.0002,
            model_type="baseline",
            out_dir="out-ralph-iter18",
            use_fhn_imex=False,
            warmup_iters=30,
            weight_decay=0.15,
        )
        .build()
    )


# Ralph Loop Iteration 19 - Smaller faster model, more iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: ~5M model should be ~2x faster → can do ~1800 iters


def ralph_iter19() -> RalphBaseConfig:
    """Ralph iteration 19 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=300,
            eval_iters=5,
            log_interval=150,
            lr_decay_iters=1200,
            max_iters=1200,
            min_lr=0.0002,
            model_type="baseline",
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter19",
            use_fhn_imex=False,
            warmup_iters=40,
        )
        .build()
    )


# Ralph Loop Iteration 20 - Smaller model with 975 iters
# GOALS: val_loss < 1.5, training_time < 100s
# Last run: 112s @ 1200 iters @ 9.77 it/s, val_loss=1.467
# Try: 975 iters should be ~100s


def ralph_iter20() -> RalphBaseConfig:
    """Ralph iteration 20 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=300,
            eval_iters=5,
            log_interval=150,
            lr_decay_iters=975,
            max_iters=975,
            min_lr=0.0002,
            model_type="baseline",
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter20",
            use_fhn_imex=False,
            warmup_iters=35,
        )
        .build()
    )


# Ralph Loop Iteration 21 - NeuroManifold with minimal FHN
# GOALS: val_loss < 1.5, training_time < 100s
# Must use NeuroManifold, not baseline!
# Strategy: Minimal FHN (1 step), no SDR/KAN/MHC


def ralph_iter21() -> RalphBaseConfig:
    """Ralph iteration 21 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=200,
            eval_iters=5,
            learning_rate=0.003,
            log_interval=100,
            lr_decay_iters=900,
            max_iters=900,
            min_lr=0.0003,
            n_fhn_steps=1,
            out_dir="out-ralph-iter21",
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 22 - Smaller NeuroManifold
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Smaller model to avoid OOM


def ralph_iter22() -> RalphBaseConfig:
    """Ralph iteration 22 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            batch_size=32,
            eval_interval=300,
            eval_iters=5,
            learning_rate=0.003,
            log_interval=150,
            lr_decay_iters=1500,
            max_iters=1500,
            min_lr=0.0003,
            n_embd=192,
            n_fhn_steps=1,
            n_head=4,
            n_layer=4,
            out_dir="out-ralph-iter22",
        )
        .build()
    )


# Ralph Loop Iteration 23 - NeuroManifold without FHN
# GOALS: val_loss < 1.5, training_time < 100s
# Test: n_fhn_steps=0 to diagnose FHN issue


def ralph_iter23() -> RalphBaseConfig:
    """Ralph iteration 23 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=250,
            eval_iters=5,
            log_interval=125,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter23",
            use_fhn_imex=False,
            warmup_iters=35,
        )
        .build()
    )


# Ralph Loop Iteration 24 - Minimal NeuroManifold to fit in memory
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter24() -> RalphBaseConfig:
    """Ralph iteration 24 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            batch_size=32,
            block_size=64,
            eval_interval=400,
            eval_iters=5,
            learning_rate=0.005,
            log_interval=200,
            lr_decay_iters=2000,
            max_iters=2000,
            min_lr=0.0005,
            n_embd=128,
            n_fhn_steps=1,
            n_head=4,
            n_layer=4,
            out_dir="out-ralph-iter24",
            warmup_iters=100,
            weight_decay=0.05,
        )
        .build()
    )


# Ralph Loop Iteration 25 - Tune FHN parameters
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: fhn_tau=1.0 for faster relaxation, higher threshold


def ralph_iter25() -> RalphBaseConfig:
    """Ralph iteration 25 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            batch_size=32,
            block_size=64,
            eval_interval=400,
            eval_iters=5,
            fhn_tau=1.0,
            fhn_threshold=0.8,
            learning_rate=0.005,
            log_interval=200,
            lr_decay_iters=2000,
            max_iters=2000,
            min_lr=0.0005,
            n_embd=128,
            n_fhn_steps=1,
            n_head=4,
            n_layer=4,
            out_dir="out-ralph-iter25",
            warmup_iters=100,
            weight_decay=0.05,
        )
        .build()
    )


# Ralph Loop Iteration 26 - Larger NeuroManifold for more capacity
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Larger model, reduced batch/block for memory


def ralph_iter26() -> RalphBaseConfig:
    """Ralph iteration 26 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            batch_size=16,
            block_size=64,
            eval_interval=500,
            eval_iters=5,
            gradient_accumulation_steps=2,
            learning_rate=0.003,
            log_interval=250,
            lr_decay_iters=3000,
            max_iters=3000,
            min_lr=0.0003,
            n_embd=256,
            n_fhn_steps=1,
            n_head=4,
            out_dir="out-ralph-iter26",
            warmup_iters=150,
        )
        .build()
    )


# Ralph Loop Iteration 27 - NeuroManifold with standard attention (n_fhn_steps=0)
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Skip FHN modulation but keep NeuroManifold architecture


def ralph_iter27() -> RalphBaseConfig:
    """Ralph iteration 27 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=300,
            eval_iters=5,
            log_interval=150,
            lr_decay_iters=975,
            max_iters=975,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter27",
            warmup_iters=35,
        )
        .build()
    )


# Ralph Loop Iteration 28 - Minimal NeuroManifold overhead
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Minimize manifold_dim/n_eigenvectors, skip FHN


def ralph_iter28() -> RalphBaseConfig:
    """Ralph iteration 28 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=300,
            eval_iters=5,
            log_interval=150,
            lr_decay_iters=975,
            max_iters=975,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter28",
            warmup_iters=35,
        )
        .build()
    )


# Ralph Loop Iteration 29 - NeuroManifold with skip_manifold_spectral
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Skip manifold/spectral computations for speed while keeping NeuroManifold


def ralph_iter29() -> RalphBaseConfig:
    """Ralph iteration 29 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=300,
            eval_iters=5,
            log_interval=150,
            lr_decay_iters=975,
            max_iters=975,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter29",
            skip_manifold_spectral=True,
            warmup_iters=35,
        )
        .build()
    )


# Ralph Loop Iteration 30 - Smaller NeuroManifold for speed
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Smaller model to increase it/s, more iterations in time budget


def ralph_iter30() -> RalphBaseConfig:
    """Ralph iteration 30 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            batch_size=48,
            eval_interval=500,
            eval_iters=5,
            learning_rate=0.003,
            log_interval=250,
            lr_decay_iters=1500,
            max_iters=1500,
            min_lr=0.0003,
            n_embd=256,
            n_head=4,
            n_layer=4,
            out_dir="out-ralph-iter30",
            skip_manifold_spectral=True,
        )
        .build()
    )


# Ralph Loop Iteration 31 - Medium NeuroManifold balancing speed/quality
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Medium model with 2000 iterations in ~90s budget


def ralph_iter31() -> RalphBaseConfig:
    """Ralph iteration 31 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            eval_interval=400,
            eval_iters=5,
            learning_rate=0.0006,
            log_interval=200,
            lr_decay_iters=1200,
            max_iters=1200,
            min_lr=6e-05,
            out_dir="out-ralph-iter31",
            skip_manifold_spectral=True,
            warmup_iters=40,
        )
        .build()
    )


# Ralph Loop Iteration 32 - NeuroManifold with torch.compile
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Use torch.compile for speedup


def ralph_iter32() -> RalphBaseConfig:
    """Ralph iteration 32 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            compile_model=True,
            eval_interval=300,
            eval_iters=5,
            log_interval=150,
            lr_decay_iters=975,
            max_iters=975,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter32",
            skip_manifold_spectral=True,
            warmup_iters=35,
        )
        .build()
    )


# Ralph Loop Iteration 35 - NeuroManifold optimized for goals
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Slightly fewer iterations to stay under 100s, higher LR for faster convergence


def ralph_iter35() -> RalphBaseConfig:
    """Ralph iteration 35 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            compile_model=True,
            eval_interval=300,
            eval_iters=5,
            learning_rate=0.0025,
            log_interval=150,
            lr_decay_iters=950,
            max_iters=950,
            min_lr=0.00025,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter35",
            skip_manifold_spectral=True,
            warmup_iters=30,
        )
        .build()
    )


# Ralph Loop Iteration 37 - NeuroManifold with Flash Attention, more iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Flash Attention allows ~1100 iterations in 100s budget


def ralph_iter37() -> RalphBaseConfig:
    """Ralph iteration 37 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            compile_model=True,
            eval_interval=350,
            eval_iters=5,
            log_interval=175,
            lr_decay_iters=1100,
            max_iters=1100,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter37",
            skip_manifold_spectral=True,
            warmup_iters=35,
        )
        .build()
    )


# Ralph Loop Iteration 38 - Push to 1200 iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 1200 iterations should fit in ~97s at 11+ it/s


def ralph_iter38() -> RalphBaseConfig:
    """Ralph iteration 38 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            compile_model=True,
            eval_interval=400,
            eval_iters=5,
            log_interval=200,
            lr_decay_iters=1200,
            max_iters=1200,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter38",
            skip_manifold_spectral=True,
            warmup_iters=40,
        )
        .build()
    )


# Ralph Loop Iteration 39 - 1150 iterations, safer timing
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 1150 iterations at 11 it/s should be ~95s


def ralph_iter39() -> RalphBaseConfig:
    """Ralph iteration 39 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=256,
            compile_model=True,
            eval_interval=380,
            eval_iters=5,
            learning_rate=0.003,
            log_interval=190,
            lr_decay_iters=1150,
            max_iters=1150,
            min_lr=0.0003,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter39",
            skip_manifold_spectral=True,
            warmup_iters=40,
        )
        .build()
    )


# Ralph Loop Iteration 40 - Smaller block_size for more speed
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: block_size=128 should give ~2x speed, allow 2000+ iterations


def ralph_iter40() -> RalphBaseConfig:
    """Ralph iteration 40 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            compile_model=True,
            eval_interval=650,
            eval_iters=5,
            log_interval=325,
            lr_decay_iters=2000,
            max_iters=2000,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter40",
            skip_manifold_spectral=True,
            warmup_iters=60,
        )
        .build()
    )


# Ralph Loop Iteration 41 - Push to 2100 iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 2100 iterations at 20 it/s should be ~98s, push loss under 1.5


def ralph_iter41() -> RalphBaseConfig:
    """Ralph iteration 41 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            compile_model=True,
            eval_interval=700,
            eval_iters=5,
            log_interval=350,
            lr_decay_iters=2100,
            max_iters=2100,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter41",
            skip_manifold_spectral=True,
            warmup_iters=65,
        )
        .build()
    )


# Ralph Loop Iteration 42 - Final push to 2200 iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 2200 iterations at 20 it/s should be ~100s, push loss under 1.5


def ralph_iter42() -> RalphBaseConfig:
    """Ralph iteration 42 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            compile_model=True,
            eval_interval=730,
            eval_iters=5,
            log_interval=365,
            lr_decay_iters=2200,
            max_iters=2200,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter42",
            skip_manifold_spectral=True,
            warmup_iters=70,
        )
        .build()
    )


# Ralph Loop Iteration 43 - 2050 iterations, stay under 100s
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 2050 iterations at 20 it/s should be ~98s


def ralph_iter43() -> RalphBaseConfig:
    """Ralph iteration 43 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            compile_model=True,
            eval_interval=680,
            eval_iters=5,
            log_interval=340,
            lr_decay_iters=2050,
            max_iters=2050,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter43",
            skip_manifold_spectral=True,
            warmup_iters=65,
        )
        .build()
    )


# Ralph Loop Iteration 45 - Larger batch for throughput
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: batch_size=96 for better GPU utilization, 2100 iterations


def ralph_iter45() -> RalphBaseConfig:
    """Ralph iteration 45 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            batch_size=96,
            compile_model=True,
            eval_interval=700,
            eval_iters=5,
            learning_rate=0.0025,
            log_interval=350,
            lr_decay_iters=2100,
            max_iters=2100,
            min_lr=0.00025,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter45",
            skip_manifold_spectral=True,
            warmup_iters=70,
        )
        .build()
    )


# Ralph Loop Iteration 46 - Optimized LR schedule
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: batch=64, block=128, 2000 iter, aggressive warmup


def ralph_iter46() -> RalphBaseConfig:
    """Ralph iteration 46 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            compile_model=True,
            dropout=0.05,
            eval_interval=650,
            eval_iters=5,
            learning_rate=0.0025,
            log_interval=325,
            lr_decay_iters=2000,
            max_iters=2000,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter46",
            skip_manifold_spectral=True,
        )
        .build()
    )


# Ralph Loop Iteration 47 - Slightly larger model for better capacity
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: n_embd=384 for more capacity, 1800 iterations


def ralph_iter47() -> RalphBaseConfig:
    """Ralph iteration 47 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            compile_model=True,
            eval_interval=600,
            eval_iters=5,
            log_interval=300,
            lr_decay_iters=1800,
            max_iters=1800,
            min_lr=0.0002,
            out_dir="out-ralph-iter47",
            skip_manifold_spectral=True,
            warmup_iters=55,
        )
        .build()
    )


# Ralph Loop Iteration 48 - 1900 iterations with larger model
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: n_embd=384, 1900 iterations should fit in ~100s


def ralph_iter48() -> RalphBaseConfig:
    """Ralph iteration 48 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            compile_model=True,
            eval_interval=630,
            eval_iters=5,
            log_interval=315,
            lr_decay_iters=1900,
            max_iters=1900,
            min_lr=0.0002,
            out_dir="out-ralph-iter48",
            skip_manifold_spectral=True,
            warmup_iters=60,
        )
        .build()
    )


# Ralph Loop Iteration 50 - Optimized learning schedule
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Reduce warmup for more effective training time


def ralph_iter50() -> RalphBaseConfig:
    """Ralph iteration 50 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            compile_model=True,
            eval_interval=700,
            eval_iters=5,
            learning_rate=0.0025,
            log_interval=350,
            lr_decay_iters=2100,
            max_iters=2100,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter50",
            skip_manifold_spectral=True,
        )
        .build()
    )


# Ralph Loop Iteration 52 - Optimized for goal
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 2050 iterations (fits in 100s at ~20 it/s), fine-tuned LR schedule


def ralph_iter52() -> RalphBaseConfig:
    """Ralph iteration 52 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            compile_model=True,
            eval_interval=680,
            eval_iters=5,
            log_interval=340,
            lr_decay_iters=2050,
            max_iters=2050,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter52",
            skip_manifold_spectral=True,
            warmup_iters=60,
        )
        .build()
    )


# Ralph Loop Iteration 53 - Ensure <100s
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 1950 iterations (fits in ~97s at 20 it/s)


def ralph_iter53() -> RalphBaseConfig:
    """Ralph iteration 53 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            compile_model=True,
            eval_interval=650,
            eval_iters=5,
            log_interval=325,
            lr_decay_iters=1950,
            max_iters=1950,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter53",
            skip_manifold_spectral=True,
            warmup_iters=60,
        )
        .build()
    )


# Ralph Loop Iteration 54 - Different seed for variance
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: Same as iter41 (best config) with seed variance


def ralph_iter54() -> RalphBaseConfig:
    """Ralph iteration 54 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            compile_model=True,
            eval_interval=700,
            eval_iters=5,
            log_interval=350,
            lr_decay_iters=2100,
            max_iters=2100,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter54",
            skip_manifold_spectral=True,
            warmup_iters=65,
        )
        .build()
    )


# Ralph Loop Iteration 56 - Optimize convergence
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 1950 iterations, lower dropout, larger batch for stability


def ralph_iter56() -> RalphBaseConfig:
    """Ralph iteration 56 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            batch_size=72,
            compile_model=True,
            dropout=0.05,
            eval_interval=650,
            eval_iters=5,
            learning_rate=0.0022,
            log_interval=325,
            lr_decay_iters=1950,
            max_iters=1950,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter56",
            skip_manifold_spectral=True,
        )
        .build()
    )


# Ralph Loop Iteration 57 - Smaller context for speed
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: block_size=96 for faster attention, more iterations


def ralph_iter57() -> RalphBaseConfig:
    """Ralph iteration 57 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=96,
            compile_model=True,
            eval_interval=800,
            eval_iters=5,
            log_interval=400,
            lr_decay_iters=2400,
            max_iters=2400,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter57",
            skip_manifold_spectral=True,
            warmup_iters=70,
        )
        .build()
    )


# Ralph Loop Iteration 58 - Fine-tuned for both goals
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: block_size=96 for speed, ~2300 iterations to stay under 100s


def ralph_iter58() -> RalphBaseConfig:
    """Ralph iteration 58 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=96,
            compile_model=True,
            eval_interval=760,
            eval_iters=5,
            log_interval=380,
            lr_decay_iters=2300,
            max_iters=2300,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter58",
            skip_manifold_spectral=True,
            warmup_iters=70,
        )
        .build()
    )


# Ralph Loop Iteration 59 - 2350 iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 2350 iterations @ ~25 it/s = ~94s, should give val_loss ~1.55


def ralph_iter59() -> RalphBaseConfig:
    """Ralph iteration 59 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=96,
            compile_model=True,
            eval_interval=780,
            eval_iters=5,
            log_interval=390,
            lr_decay_iters=2350,
            max_iters=2350,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter59",
            skip_manifold_spectral=True,
            warmup_iters=70,
        )
        .build()
    )


# Ralph Loop Iteration 60 - Push to 2380 iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 2380 iterations @ ~25 it/s = ~95s + 5s startup = ~100s


def ralph_iter60() -> RalphBaseConfig:
    """Ralph iteration 60 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=96,
            compile_model=True,
            eval_interval=790,
            eval_iters=5,
            log_interval=395,
            lr_decay_iters=2380,
            max_iters=2380,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter60",
            skip_manifold_spectral=True,
            warmup_iters=70,
        )
        .build()
    )


# Ralph Loop Iteration 61 - Push to 2390 iterations
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter61() -> RalphBaseConfig:
    """Ralph iteration 61 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=96,
            compile_model=True,
            eval_interval=795,
            eval_iters=5,
            log_interval=397,
            lr_decay_iters=2390,
            max_iters=2390,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter61",
            skip_manifold_spectral=True,
            warmup_iters=70,
        )
        .build()
    )


# Ralph Loop Iteration 62 - Minimize eval overhead
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 2400 iterations, minimal eval to save time


def ralph_iter62() -> RalphBaseConfig:
    """Ralph iteration 62 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=96,
            compile_model=True,
            eval_interval=2400,
            eval_iters=3,
            log_interval=800,
            lr_decay_iters=2400,
            max_iters=2400,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter62",
            skip_manifold_spectral=True,
            warmup_iters=70,
        )
        .build()
    )


# Ralph Loop Iteration 63 - Very small block_size for speed
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: block_size=80, 2600 iterations


def ralph_iter63() -> RalphBaseConfig:
    """Ralph iteration 63 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            eval_interval=2600,
            eval_iters=3,
            log_interval=870,
            lr_decay_iters=2600,
            max_iters=2600,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter63",
            skip_manifold_spectral=True,
            warmup_iters=80,
        )
        .build()
    )


# Ralph Loop Iteration 64 - 2500 iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: block_size=80 @ 26 it/s, 2500 iters = ~96s


def ralph_iter64() -> RalphBaseConfig:
    """Ralph iteration 64 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            eval_interval=2500,
            eval_iters=3,
            log_interval=835,
            lr_decay_iters=2500,
            max_iters=2500,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter64",
            skip_manifold_spectral=True,
            warmup_iters=75,
        )
        .build()
    )


# Ralph Loop Iteration 65 - 2600 iterations at higher throughput
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: block_size=80 @ ~28 it/s, 2600 iters = ~93s


def ralph_iter65() -> RalphBaseConfig:
    """Ralph iteration 65 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            eval_interval=2600,
            eval_iters=3,
            log_interval=870,
            lr_decay_iters=2600,
            max_iters=2600,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter65",
            skip_manifold_spectral=True,
            warmup_iters=80,
        )
        .build()
    )


# Ralph Loop Iteration 66 - 2700 iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: block_size=80 @ ~29 it/s, 2700 iters = ~93s


def ralph_iter66() -> RalphBaseConfig:
    """Ralph iteration 66 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            eval_interval=2700,
            eval_iters=3,
            log_interval=900,
            lr_decay_iters=2700,
            max_iters=2700,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter66",
            skip_manifold_spectral=True,
            warmup_iters=80,
        )
        .build()
    )


# Ralph Loop Iteration 67 - 2800 iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: block_size=80 @ ~28 it/s, 2800 iters = ~100s


def ralph_iter67() -> RalphBaseConfig:
    """Ralph iteration 67 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            eval_interval=2800,
            eval_iters=3,
            log_interval=935,
            lr_decay_iters=2800,
            max_iters=2800,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter67",
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 68 - 2850 iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: block_size=80 @ ~28 it/s, 2850 iters = ~102s (might be tight)


def ralph_iter68() -> RalphBaseConfig:
    """Ralph iteration 68 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            eval_interval=2850,
            eval_iters=3,
            log_interval=950,
            lr_decay_iters=2850,
            max_iters=2850,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter68",
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 70 - Push to 2900 iterations
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 2900 iterations at ~28 it/s should be ~103s but variance might help


def ralph_iter70() -> RalphBaseConfig:
    """Ralph iteration 70 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            dropout=0.08,
            eval_interval=2900,
            eval_iters=3,
            log_interval=970,
            lr_decay_iters=2900,
            max_iters=2900,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter70",
            skip_manifold_spectral=True,
            warmup_iters=90,
        )
        .build()
    )


# Ralph Loop Iteration 71 - 2800 iterations with lower dropout
# GOALS: val_loss < 1.5, training_time < 100s
# Strategy: 2800 iterations, dropout=0.08 helped in iter70


def ralph_iter71() -> RalphBaseConfig:
    """Ralph iteration 71 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            dropout=0.08,
            eval_interval=2800,
            eval_iters=3,
            log_interval=935,
            lr_decay_iters=2800,
            max_iters=2800,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter71",
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 72 - 2850 iterations with lower dropout
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter72() -> RalphBaseConfig:
    """Ralph iteration 72 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            dropout=0.08,
            eval_interval=2850,
            eval_iters=3,
            log_interval=950,
            lr_decay_iters=2850,
            max_iters=2850,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter72",
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 74 - 2820 iterations for sub-100s
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter74() -> RalphBaseConfig:
    """Ralph iteration 74 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            dropout=0.08,
            eval_interval=2820,
            eval_iters=3,
            log_interval=940,
            lr_decay_iters=2820,
            max_iters=2820,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter74",
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 76 - 2840 iterations, sweet spot
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter76() -> RalphBaseConfig:
    """Ralph iteration 76 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            dropout=0.08,
            eval_interval=2840,
            eval_iters=3,
            log_interval=945,
            lr_decay_iters=2840,
            max_iters=2840,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter76",
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 78 - 2830 iterations
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter78() -> RalphBaseConfig:
    """Ralph iteration 78 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            dropout=0.08,
            eval_interval=2830,
            eval_iters=3,
            log_interval=945,
            lr_decay_iters=2830,
            max_iters=2830,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter78",
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 80 - Minimal eval overhead
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter80() -> RalphBaseConfig:
    """Ralph iteration 80 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            dropout=0.08,
            eval_interval=2850,
            eval_iters=2,
            log_interval=1000,
            lr_decay_iters=2850,
            max_iters=2850,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter80",
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 85 - Push convergence with lower dropout
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter85() -> RalphBaseConfig:
    """Ralph iteration 85 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            dropout=0.06,
            eval_interval=2870,
            eval_iters=2,
            log_interval=955,
            lr_decay_iters=2870,
            max_iters=2870,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter85",
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 88 - Push convergence with dropout=0.07
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter88() -> RalphBaseConfig:
    """Ralph iteration 88 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            dropout=0.08,
            eval_interval=2850,
            eval_iters=2,
            log_interval=950,
            lr_decay_iters=2850,
            max_iters=2850,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter88",
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 107 - Lower dropout for better convergence
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter107() -> RalphBaseConfig:
    """Ralph iteration 107 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            dropout=0.075,
            eval_interval=2850,
            eval_iters=3,
            log_interval=950,
            lr_decay_iters=2850,
            max_iters=2850,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter107",
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 115 - Same as 72 but with checkpoint saving
# GOALS: val_loss < 1.5, training_time < 100s


def ralph_iter115() -> RalphBaseConfig:
    """Ralph iteration 115 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            block_size=80,
            compile_model=True,
            dropout=0.08,
            eval_interval=2850,
            eval_iters=3,
            log_interval=950,
            lr_decay_iters=2850,
            max_iters=2850,
            min_lr=0.0002,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter115",
            save_checkpoints=True,
            skip_manifold_spectral=True,
            warmup_iters=85,
        )
        .build()
    )


# Ralph Loop Iteration 116 - Push for val_loss < 1.5 AND time < 100s
# Strategy: Slightly more iterations (2900), larger batch for faster throughput


def ralph_iter116() -> RalphBaseConfig:
    """Ralph iteration 116 configuration."""
    return (
        RalphConfigBuilder()
        .with_overrides(
            batch_size=96,
            block_size=80,
            compile_model=True,
            dropout=0.06,
            eval_interval=2700,
            eval_iters=3,
            learning_rate=0.0025,
            log_interval=900,
            lr_decay_iters=2700,
            max_iters=2700,
            min_lr=0.00025,
            n_embd=320,
            n_head=5,
            out_dir="out-ralph-iter116",
            save_checkpoints=True,
            skip_manifold_spectral=True,
            warmup_iters=80,
        )
        .build()
    )
