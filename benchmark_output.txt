================================================================================
SpectralDecomposition torch.compile Benchmark
================================================================================
Device: cuda

Configuration:
  Iterations: 30
  Warmup: 3
  Dtype: bfloat16

================================================================================
Sequence Length: 64, Batch Size: 2
Manifold Dim: 64, Eigenvectors: 32
--------------------------------------------------------------------------------
Benchmarking without torch.compile (baseline)...
Benchmarking with torch.compile (optimized)...

Results:
--------------------------------------------------------------------------------
Forward Pass (ms):
  Baseline:  2.723
  Compiled:  2.812
  Speedup:   0.97x (-3.2% faster)

Backward Pass (ms):
  Baseline:  8.219
  Compiled:  8.529
  Speedup:   0.96x (-3.6% faster)

Total Time (ms):
  Baseline:  10.942
  Compiled:  11.341
  Speedup:   0.96x (-3.5% faster)

================================================================================
Sequence Length: 128, Batch Size: 1
Manifold Dim: 64, Eigenvectors: 32
--------------------------------------------------------------------------------
Benchmarking without torch.compile (baseline)...
Benchmarking with torch.compile (optimized)...

Results:
--------------------------------------------------------------------------------
Forward Pass (ms):
  Baseline:  2.883
  Compiled:  1.989
  Speedup:   1.45x (44.9% faster)

Backward Pass (ms):
  Baseline:  13.333
  Compiled:  7.350
  Speedup:   1.81x (81.4% faster)

Total Time (ms):
  Baseline:  16.217
  Compiled:  9.339
  Speedup:   1.74x (73.6% faster)

================================================================================
Benchmark complete

Summary:
--------------------------------------------------------------------------------
torch.compile successfully optimizes the full SpectralDecomposition module
by fusing the spectral_proj layers (Linear -> SiLU -> Linear) with
subsequent operations (L2 norm, bmm for ortho loss).

Expected improvement: 15-40% speedup from end-to-end kernel fusion
Actual results documented above.
================================================================================
